{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib \n",
    "from scipy import optimize\n",
    "from scipy import stats\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "#plt.rcParams['font.family'] = 'IPAexGothic'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # warningが出ないように設定\n",
    "pd.set_option(\"display.max_rows\", None) # pandasの表示上限をなくす\n",
    "pd.set_option(\"display.max_columns\", None) # pandasの表示上限をなくす\n",
    "\n",
    "import gensim\n",
    "\n",
    "model = gensim.models.Word2Vec.load(\"latest-ja-word2vec-gensim-model/word2vec.gensim.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "f = open(\"9_relatoinvec_list\",'rb')\n",
    "mean_vec_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1275"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mean_vec_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入力単語\n",
    "\n",
    "imput_word_list = ['太陽光発電', \"住宅\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 関係ベクトルに入力単語のベクトルを加算, 減算\n",
    "\n",
    "result_vec_list  = []\n",
    "\n",
    "for w in imput_word_list:\n",
    "\n",
    "    w_to_v = model.wv[w]\n",
    "\n",
    "    for mean_vec in mean_vec_list:\n",
    "        result_vec_plus = w_to_v - mean_vec \n",
    "        result_vec_minus =   w_to_v + mean_vec \n",
    "    \n",
    "        result_vec_list.append(result_vec_plus)\n",
    "        result_vec_list.append(result_vec_minus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5100"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 推定ベクトル数\n",
    "\n",
    "len(result_vec_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 登録済固有名詞リスト\n",
    "\n",
    "f = open(\"./koyuu_noun_list.binaryfile\",'rb')\n",
    "noun_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推定ベクトルと類似度が高い単語をn個上位表示\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "output_word_list = []\n",
    "max_n = 10\n",
    "\n",
    "for vec in result_vec_list:\n",
    "    most_similar = np.array(list(model.wv.most_similar([vec], [], max_n)))\n",
    "    \n",
    "    output_word_list.extend(most_similar[:,0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48550\n",
      "46100\n"
     ]
    }
   ],
   "source": [
    "#インプットした単語と同じ単語は除去\n",
    "\n",
    "for imput_word in imput_word_list:\n",
    "    output_word_list = [output_word for output_word in output_word_list if output_word != imput_word]\n",
    "    print(len(output_word_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 固有名詞リスト外の単語は除去\n",
    "# これをすると単語が消える=>普通名詞の関係ベクトルは普通名詞を推定しやすい\n",
    "\n",
    "output_word_list = [output_word for output_word in output_word_list if noun_list.count(output_word)>=1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('リアビュー', 1),\n",
       " ('温水', 2),\n",
       " ('リアプロジェクションテレビ', 2),\n",
       " ('原水', 2),\n",
       " ('長屋', 2),\n",
       " ('関西電力', 4),\n",
       " ('田畑', 11),\n",
       " ('町屋', 16),\n",
       " ('もんじゅ', 18),\n",
       " ('コジェネレーション', 21),\n",
       " ('センサ', 31),\n",
       " ('エコキュート', 37),\n",
       " ('サッフォー', 200),\n",
       " ('澹', 200),\n",
       " ('ヒートポンプ', 639)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#共起単語と共起回数をdic化してまとめる\n",
    "\n",
    "import collections\n",
    "\n",
    "c = collections.Counter(output_word_list)\n",
    "c = sorted(c.items(), key=lambda x:x[1])\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for taple in c:\n",
    "    word = taple[0]\n",
    "    num = taple[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
